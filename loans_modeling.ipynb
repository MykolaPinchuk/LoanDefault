{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68effbd-85fb-4174-adc6-c49ecd2affac",
   "metadata": {},
   "source": [
    "## This is Prod script for loan default prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a31c8d-daa5-4292-aa7c-2d937040fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, time, warnings, gzip, gc, random, math, shap, pickle, optuna, csv, sys, re\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, KFold\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from category_encoders import MEstimateEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from google.cloud import bigquery, storage\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "app_folder = '/home/jupyter/project_repos/LoanDefault/loans-app'\n",
    "data_path = '/home/jupyter/projects_data/loans'\n",
    "project_name = 'My First Project'\n",
    "project_id = 'quantum-keep-360100'\n",
    "regionn = 'us-central1'\n",
    "\n",
    "ml_project_name = 'loans'\n",
    "model_name = 'XGB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a30834f-d5ba-495e-8cee-4c4e47dc40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### target encoding ###\n",
    "# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n",
    "\n",
    "class CrossFoldEncoder:\n",
    "    def __init__(self, encoder, **kwargs):\n",
    "        self.encoder_ = encoder\n",
    "        self.kwargs_ = kwargs  # keyword arguments for the encoder\n",
    "        self.cv_ = KFold(n_splits=4)\n",
    "\n",
    "    # Fit an encoder on one split and transform the feature on the\n",
    "    # other. Iterating over the splits in all folds gives a complete\n",
    "    # transformation. We also now have one trained encoder on each\n",
    "    # fold.\n",
    "    def fit_transform(self, X, y, cols):\n",
    "        self.fitted_encoders_ = []\n",
    "        self.cols_ = cols\n",
    "        X_encoded = []\n",
    "        for idx_encode, idx_train in self.cv_.split(X):\n",
    "            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n",
    "            fitted_encoder.fit(\n",
    "                X.iloc[idx_encode, :], y.iloc[idx_encode],\n",
    "            )\n",
    "            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n",
    "            self.fitted_encoders_.append(fitted_encoder)\n",
    "        X_encoded = pd.concat(X_encoded)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X_encoded\n",
    "\n",
    "    # To transform the test data, average the encodings learned from\n",
    "    # each fold.\n",
    "    def transform(self, X):\n",
    "        from functools import reduce\n",
    "\n",
    "        X_encoded_list = []\n",
    "        for fitted_encoder in self.fitted_encoders_:\n",
    "            X_encoded = fitted_encoder.transform(X)\n",
    "            X_encoded_list.append(X_encoded[self.cols_])\n",
    "        X_encoded = reduce(\n",
    "            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n",
    "        ) / len(X_encoded_list)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52088471-6bba-488a-94bb-0a1eb779fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "\n",
    "os.chdir(data_path)\n",
    "with open(data_path + '/LCLoans_141_800k.pkl', 'rb') as pickled_one:\n",
    "    df = pickle.load(pickled_one)\n",
    "    \n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbfe9a-a2da-4de9-8128-41ce066a9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tokeep = ['id', 'loan_status',\n",
    " 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment','issue_d',\n",
    " 'purpose', 'title', 'initial_list_status', 'application_type',\n",
    " 'grade', 'sub_grade', 'fico_range_high',\n",
    " 'emp_title', 'emp_length', 'home_ownership', 'annual_inc', 'zip_code', 'addr_state',\n",
    " 'dti',           \n",
    " 'verification_status', \n",
    " 'mo_sin_rcnt_tl', 'mths_since_last_delinq', 'mths_since_last_major_derog', 'mths_since_last_record',\n",
    " 'mths_since_recent_bc_dlq', 'mths_since_recent_revol_delinq',\n",
    " 'num_tl_op_past_12m', \n",
    " 'earliest_cr_line', 'inq_last_6mths', 'inq_fi', 'inq_last_12m',\n",
    " 'open_acc', 'acc_open_past_24mths', 'mort_acc', 'total_acc',\n",
    " 'avg_cur_bal', 'il_util', 'tot_cur_bal', \n",
    " 'revol_bal', 'revol_util', 'max_bal_bc', 'bc_open_to_buy', 'mo_sin_rcnt_rev_tl_op', 'num_actv_rev_tl', 'num_op_rev_tl', 'total_rev_hi_lim',               \n",
    " 'delinq_2yrs', 'acc_now_delinq', 'delinq_amnt', 'pub_rec', 'pub_rec_bankruptcies',\n",
    " 'annual_inc_joint', 'dti_joint', 'verification_status_joint',\n",
    " 'total_bal_ex_mort', 'tot_coll_amt', 'tax_liens', 'percent_bc_gt_75', 'pct_tl_nvr_dlq', \n",
    " 'open_rv_12m', 'open_il_12m', 'num_tl_90g_dpd_24m', 'num_tl_30dpd', 'num_tl_120dpd_2m',\n",
    " 'num_accts_ever_120_pd',\n",
    " 'recoveries', 'total_rec_prncp', 'total_rec_int']\n",
    "\n",
    "df = df[features_tokeep]\n",
    "gc.collect()\n",
    "\n",
    "recoveries = df[df.loan_status.isin(['Charged Off', 'Default'])][[\n",
    "    'id', 'loan_status', 'recoveries', 'loan_amnt', 'int_rate', 'total_rec_prncp', 'total_rec_int']]\n",
    "\n",
    "df.drop(columns = ['recoveries', 'total_rec_prncp', 'total_rec_int'], inplace=True)\n",
    "# this removes all features, not known to investors ex ante.\n",
    "\n",
    "df.drop(columns = ['il_util', 'max_bal_bc'], inplace=True)\n",
    "# these are useful features, which I will preprocess later\n",
    "\n",
    "df.issue_d = df.issue_d.astype('O')\n",
    "df.issue_d = pd.to_datetime(df.issue_d, format='%b-%Y')\n",
    "df['year_issued']=df.issue_d.dt.year\n",
    "    \n",
    "#df = df.sample(200000, random_state=1)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "display(df.shape, time.time()-time0, df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4f96d-9800-4574-947c-b05bac01a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some very rare loan types:\n",
    "\n",
    "df = df[~df.purpose.isin(['educational', 'renewable_energy', 'wedding'])]\n",
    "df.purpose = df.purpose.cat.remove_categories(['educational', 'renewable_energy', 'wedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4910bdd-32a3-42b4-b217-1dc2ddc37c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean time features\n",
    "\n",
    "df.earliest_cr_line = df.earliest_cr_line.astype('O')\n",
    "df.earliest_cr_line = pd.to_datetime(df.earliest_cr_line, format='%b-%Y')\n",
    "df['month_issued']=df.issue_d.dt.month\n",
    "df['year_earliest']=df.issue_d.dt.year\n",
    "df['years_borrowing'] = (df.issue_d - df.earliest_cr_line)/ np.timedelta64(1, 'Y')\n",
    "df['pub_rec_pa'] = df.pub_rec/df.years_borrowing\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28acea2a-2632-431f-bde7-1c8a3c0e8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a target variable\n",
    "\n",
    "display(df.loan_status.value_counts())\n",
    "df.target=np.nan\n",
    "#df.loc[df.loan_status.isin(['Fully Paid', 'Does not meet the credit policy. Status:Fully Paid']), 'target']=0\n",
    "#df.loc[df.loan_status.isin(['Charged Off', 'Late (31-120 days)', 'Does not meet the credit policy. Status:Charged Off', 'Default']), 'target']=1\n",
    "df.loc[df.loan_status.isin(['Fully Paid']), 'target']=0\n",
    "df.loc[df.loan_status.isin(['Charged Off', 'Default']), 'target']=1\n",
    "df=df[df['target'].isin([0,1])]\n",
    "display(df.shape,df.loan_status.value_counts(), df.count(), sys.getsizeof(df)/1048576)\n",
    "df.drop(columns='loan_status',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35726a-5ceb-4d5f-a33b-63c106f048d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add key loan features, scaled by borrower's income:\n",
    "\n",
    "df.loc[df.annual_inc<1,'annual_inc']=1\n",
    "df['lti']=df.loan_amnt/df.annual_inc\n",
    "df['iti']=(df.installment*12)/df.annual_inc\n",
    "df.loc[df.lti==np.inf, 'lti']=np.nan\n",
    "df.loc[df.lti>1.5, 'lti']=1.5\n",
    "df.loc[df.iti==np.inf, 'iti']=np.nan\n",
    "df.loc[df.iti>1, 'iti']=1\n",
    "df.loc[df.revol_util>100,'revol_util']=100\n",
    "df.loc[df.dti>100, 'dti']=100\n",
    "df.loc[df.dti<0, 'dti']=0\n",
    "\n",
    "df['revol_balance_income'] = df.revol_bal/df.annual_inc\n",
    "df['avg_cur_bal_inc'] = df.avg_cur_bal/df.annual_inc\n",
    "df['tot_cur_bal_inc'] = df.tot_cur_bal/df.annual_inc\n",
    "df['total_bal_ex_mort_inc'] = df.total_bal_ex_mort/df.annual_inc\n",
    "df['total_rev_inc'] = df.total_rev_hi_lim/df.annual_inc\n",
    "df['open_cl_ratio']=df.open_acc/df.total_acc\n",
    "\n",
    "# add more features\n",
    "\n",
    "df['zip_code'] = df.zip_code.str.rstrip('xx').astype(int)\n",
    "df['joint'] = df.dti_joint.notnull().astype(int)\n",
    "df['emp_length'] = df.emp_length.str.rstrip(' years')\n",
    "df.loc[df.emp_length=='< 1','emp_length'] = 0\n",
    "df.loc[df.emp_length=='10+','emp_length'] = 10\n",
    "df['emp_length'] = df.emp_length.astype(np.float32)\n",
    "display(df.emp_length.value_counts())\n",
    "df.amnt_same = (df.loan_amnt == df.funded_amnt_inv).astype(int)\n",
    "df['low_fico'] = (df.fico_range_high<=659).astype(int)\n",
    "df.loc[df.home_ownership.isin(['ANY','NONE','OTHER']), 'home_ownership'] = 'OTHER'\n",
    "df['was_bankrupt'] = (df.pub_rec_bankruptcies>0).astype(int)\n",
    "\n",
    "df.drop(columns = ['annual_inc_joint', 'dti_joint', 'verification_status_joint', 'earliest_cr_line', 'issue_d'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d62ab-ec16-4a4d-b6d6-bd0a1653c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For features like 'time_since some credit event', treat NA as never and fill those values with 100 years equivalent\n",
    "\n",
    "df.mo_sin_rcnt_tl = df.mo_sin_rcnt_tl.fillna(value=120)\n",
    "df.num_tl_op_past_12m = df.num_tl_op_past_12m.fillna(value=0)\n",
    "\n",
    "months_since_col = ['mths_since_last_delinq', 'mths_since_last_major_derog', \n",
    "                    'mths_since_last_record', 'mths_since_recent_bc_dlq', 'mths_since_recent_revol_delinq']\n",
    "\n",
    "for col in months_since_col:\n",
    "    df[col] = df[col].fillna(value=1200)\n",
    "\n",
    "#display(df.count())\n",
    "\n",
    "df.inq_fi = df.inq_fi.fillna(value=0)\n",
    "df.inq_last_12m = df.inq_last_12m.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a8e9d-d996-4a65-a49a-00d2a573c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_te = ['sub_grade', 'emp_title', 'purpose', 'title', 'zip_code', 'addr_state', 'grade', 'home_ownership']\n",
    "cat_features_ohe = ['verification_status', 'initial_list_status', 'application_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce74ee85-8151-479c-9a80-57e16ddf99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(df.count())\n",
    "\n",
    "features_fill_M = ['emp_title', 'title']\n",
    "features_fill_med = ['dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_util', \n",
    "                     'total_acc', 'mort_acc', 'pub_rec_bankruptcies', 'bc_open_to_buy','tot_cur_bal_inc', 'total_rev_inc',\n",
    "                    'total_bal_ex_mort_inc', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'avg_cur_bal_inc',\n",
    "                    'mo_sin_rcnt_rev_tl_op', 'num_actv_rev_tl', 'num_op_rev_tl', 'tax_liens']\n",
    "features_fill_zero = ['open_rv_12m', 'open_il_12m', 'emp_length', 'num_tl_90g_dpd_24m', \n",
    "                      'num_tl_30dpd', 'num_tl_120dpd_2m', 'num_accts_ever_120_pd',\n",
    "                     'acc_open_past_24mths', 'tot_coll_amt']\n",
    "\n",
    "for col in features_fill_zero:\n",
    "    df[col] = df[col].fillna(value=0)\n",
    "\n",
    "for col in features_fill_M:\n",
    "    df[col] = df[col].cat.add_categories(['MISSING']) \n",
    "    df[col] = df[col].fillna(value='MISSING')\n",
    "    \n",
    "test_size = 0.25\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "random.seed(2)\n",
    "test_index = random.sample(list(df.index), int(test_size*df.shape[0]))\n",
    "train = df.iloc[list(set(df.index)-set(test_index))]\n",
    "test = df.iloc[test_index]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "test00 = test.copy()\n",
    "train.drop(columns=['id'],inplace=True)\n",
    "test.drop(columns=['id'],inplace=True)\n",
    "display(train.shape, test.shape, train.head(3), test.head(3))\n",
    "\n",
    "for col in features_fill_med:\n",
    "    train[col] = train[col].fillna(train[col].median())\n",
    "    test[col] = test[col].fillna(train[col].median())\n",
    "    \n",
    "train['total_rev_hi_lim'] = train.total_rev_inc.median()*train.annual_inc\n",
    "test['total_rev_hi_lim'] = train.total_rev_inc.median()*test.annual_inc\n",
    "\n",
    "train['total_bal_ex_mort'] = train.total_bal_ex_mort_inc.median()*train.annual_inc\n",
    "test['total_bal_ex_mort'] = train.total_bal_ex_mort_inc.median()*test.annual_inc\n",
    "\n",
    "train['tot_cur_bal'] = train.tot_cur_bal_inc.median()*train.annual_inc\n",
    "test['tot_cur_bal'] = train.tot_cur_bal_inc.median()*test.annual_inc\n",
    "\n",
    "train['avg_cur_bal'] = train.avg_cur_bal_inc.median()*train.annual_inc\n",
    "test['avg_cur_bal'] = train.avg_cur_bal_inc.median()*test.annual_inc\n",
    "\n",
    "display(train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbca162-25b4-428c-8fb2-e5513b248035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TE for categorical features\n",
    "\n",
    "time1 = time.time()\n",
    "encoder = CrossFoldEncoder(MEstimateEncoder, m=10)\n",
    "train_encoded = encoder.fit_transform(train, train.target, cols=cat_features_te)\n",
    "test_encoded = encoder.transform(test)\n",
    "\n",
    "freq_enc = (train.groupby('title').size()) / len(train)\n",
    "train['title_fencoded'] = train['title'].apply(lambda x : freq_enc[x])\n",
    "test['title_fencoded'] = test['title'].apply(lambda x : freq_enc[x])\n",
    "\n",
    "train.drop(columns=cat_features_te, inplace=True)\n",
    "test.drop(columns=cat_features_te,  inplace=True)\n",
    "train = pd.concat([train, train_encoded], axis = 1)\n",
    "test = pd.concat([test, test_encoded], axis = 1)\n",
    "\n",
    "display(time.time()-time0, time.time()-time1)\n",
    "display(train.shape, train.head(), train.count())\n",
    "train0 = train.copy()\n",
    "test0 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8421472-7cf2-476e-a7ed-9fada5933306",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "y_train = X_train.pop('target')\n",
    "X_test = test.copy()\n",
    "y_test = X_test.pop('target')\n",
    "display(X_test.head())\n",
    "\n",
    "### Do OHE for some features ###\n",
    "\n",
    "feature_transformer = ColumnTransformer([\n",
    "    (\"cat\", \n",
    "     OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), \n",
    "     cat_features_ohe)], \n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "print('Number of features before transaformation: ', X_train.shape)\n",
    "X_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\n",
    "X_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\n",
    "X_train.columns = X_train.columns.str.replace(r'^cat__', '').str.replace(r'^remainder__', '')\n",
    "X_test.columns = X_test.columns.str.replace(r'^cat__', '').str.replace(r'^remainder__', '')\n",
    "\n",
    "print('time to do feature proprocessing: ', time.time()-time1)\n",
    "print('Number of features after transaformation: ', X_train.shape)\n",
    "\n",
    "feature_set = ['term', \n",
    "               'dti', \n",
    "               'acc_open_past_24mths', \n",
    "               'lti', \n",
    "               'sub_grade_encoded', \n",
    "               'emp_title_encoded',\n",
    "               'home_ownership_encoded']\n",
    "X_train = X_train[feature_set]\n",
    "X_test = X_test[feature_set]\n",
    "\n",
    "X_train.head()\n",
    "X_test_0 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cda547-acf5-4da2-a515-932f7cdee179",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b3ee5-7239-4b17-8d8a-366e44a41673",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "xgbb = XGBClassifier(tree_method = 'gpu_hist',\n",
    "                    n_estimators = 200,\n",
    "                    eta = 0.08,\n",
    "                    max_depth = 5,\n",
    "                    subsample = 0.8,\n",
    "                    colsample_bytree = 0.6)\n",
    "\n",
    "xgbb.fit(X_train, y_train)\n",
    "\n",
    "precision_t, recall_t, threshold = precision_recall_curve(y_train, xgbb.predict_proba(X_train)[:, 1])\n",
    "auc_precision_recall_train = auc(recall_t, precision_t)\n",
    "temp = recall_t[(recall_t>0.095)&(recall_t<0.105)]\n",
    "temp = temp[int(len(temp)/2)]\n",
    "indexx = ((np.where(recall_t==temp)))[0][0]\n",
    "r10prec_train = precision_t[indexx]\n",
    "precision_t, recall_t, threshold = precision_recall_curve(y_test, xgbb.predict_proba(X_test)[:, 1])\n",
    "auc_precision_recall_test = auc(recall_t, precision_t)\n",
    "temp = recall_t[(recall_t>0.095)&(recall_t<0.105)]\n",
    "temp = temp[int(len(temp)/2)]\n",
    "indexx = ((np.where(recall_t==temp)))[0][0]\n",
    "r10prec_test = precision_t[indexx]\n",
    "\n",
    "display('Train Accuracy: ', accuracy_score(y_train, xgbb.predict(X_train)))\n",
    "display('F1 score: ', f1_score(y_train, xgbb.predict(X_train)))\n",
    "display('ROCAUC: ', roc_auc_score(y_train, xgbb.predict(X_train)))\n",
    "display('PRAUC: ', auc_precision_recall_train)\n",
    "display('R10P: ', r10prec_train)\n",
    "\n",
    "# Performance evaluation:\n",
    "display('Test Accuracy: ', accuracy_score(y_test, xgbb.predict(X_test)))\n",
    "display('F1 score: ', f1_score(y_test, xgbb.predict(X_test)))\n",
    "display('ROCAUC: ', roc_auc_score(y_test, xgbb.predict(X_test)))\n",
    "display('PRAUC: ', auc_precision_recall_test)\n",
    "display('R10P: ', r10prec_test)\n",
    "display(time.time()-time1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall_t, precision_t, color='purple')\n",
    "ax.set_title('Precision-Recall Curve, test')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylim(bottom=0, top=1.02)\n",
    "plt.show()\n",
    "\n",
    "xgb_model = xgbb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a54d36-d0e4-48fc-965d-5a4156c7bc0d",
   "metadata": {},
   "source": [
    "#### Save model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dff8c9-9401-4c53-848b-ee498796a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bucket = 'gs://pmykola-projectsgcp-artifacts/loans'\n",
    "storage_path = os.path.join(model_bucket, artifact_filename_rf)\n",
    "blob = storage.blob.Blob.from_string(storage_path, \n",
    "                                     client=storage.Client(project=project_id))\n",
    "blob.upload_from_filename(os.getcwd()+'/'+artifact_filename_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185e119-1e8f-407e-8466-b8a228965216",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(artifact_filename_rf, \"rb\")\n",
    "trained_model = joblib.load(file)\n",
    "prediction = trained_model.predict([list(X_test.iloc[0,:])])\n",
    "print(f'''lm prediction: {prediction}. \n",
    "Total time is {time.time()-time0} sec''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28143aba-e6cc-49d7-8831-435ff5844b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf4a50-cc70-4b9f-a34d-25657c843c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b191b33a-fa11-46bc-8795-ce1dfb296198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[0.4651663899421692, 0.3640084266662598]\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "payload = {'instances': [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 2.40000000e+03, 6.00000000e+03, 2.40000000e+03,\n",
    "       6.00000000e+01, 3.59600000e+01, 8.43300018e+01, 4.39000000e+02,\n",
    "       1.00000000e+01, 1.22520000e+03, 8.72000027e+00, 1.20000000e+02,\n",
    "       1.20000000e+01, 1.20000000e+01, 1.20000000e+01, 1.20000000e+01,\n",
    "       1.20000000e+01, 0.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 2.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
    "       1.00000000e+01, 1.39509436e+03, 1.50214629e+04, 2.95600000e+03,\n",
    "       9.85000000e+01, 5.20100000e+03, 8.00000000e+00, 5.00000000e+00,\n",
    "       7.00000000e+00, 4.71702002e+03, 0.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.95045752e+03,\n",
    "       0.00000000e+00, 0.00000000e+00, 4.00000000e+01, 9.90000000e+01,\n",
    "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 0.00000000e+00, 2.01100000e+03, 1.20000000e+01,\n",
    "       2.01100000e+03, 1.00809736e+01, 0.00000000e+00, 1.95886388e-01,\n",
    "       8.25954974e-02, 2.41266727e-01, 1.13866664e-01, 1.22604167e+00,\n",
    "       5.67291677e-01, 3.84999990e-01, 2.00000003e-01, 0.00000000e+00,\n",
    "       0.00000000e+00, 0.00000000e+00, 2.39409138e-06, 2.55292868e-01,\n",
    "       2.61714582e-01, 2.84216317e-01, 1.94365262e-01, 1.70245004e-01,\n",
    "       1.75577218e-01, 2.19904579e-01, 2.25602507e-01], \n",
    "                         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 2.40000000e+03, 6.00000000e+03, 2.40000000e+03,\n",
    "       3.60000000e+01, 1.59600000e+01, 8.43300018e+01, 4.39000000e+02,\n",
    "       1.00000000e+01, 1.22520000e+03, 8.72000027e+00, 1.20000000e+02,\n",
    "       1.20000000e+01, 1.20000000e+01, 1.20000000e+01, 1.20000000e+01,\n",
    "       1.20000000e+01, 0.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 2.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
    "       1.00000000e+01, 1.39509436e+03, 1.50214629e+04, 2.95600000e+03,\n",
    "       9.85000000e+01, 5.20100000e+03, 8.00000000e+00, 5.00000000e+00,\n",
    "       7.00000000e+00, 4.71702002e+03, 0.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.95045752e+03,\n",
    "       0.00000000e+00, 0.00000000e+00, 4.00000000e+01, 9.90000000e+01,\n",
    "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 0.00000000e+00, 2.01100000e+03, 1.20000000e+01,\n",
    "       2.01100000e+03, 1.00809736e+01, 0.00000000e+00, 1.95886388e-01,\n",
    "       8.25954974e-02, 2.41266727e-01, 1.13866664e-01, 1.22604167e+00,\n",
    "       5.67291677e-01, 3.84999990e-01, 2.00000003e-01, 0.00000000e+00,\n",
    "       0.00000000e+00, 0.00000000e+00, 2.39409138e-06, 2.55292868e-01,\n",
    "       2.61714582e-01, 2.84216317e-01, 1.94365262e-01, 1.70245004e-01,\n",
    "       1.75577218e-01, 2.19904579e-01, 2.25602507e-01]]}\n",
    "\n",
    "# Parse JSON\n",
    "with open('request.json', 'w') as outfile:\n",
    "    json.dump(payload, outfile)\n",
    "\n",
    "!gcloud ai endpoints predict $endpoint_id \\\n",
    "  --region=$regionn \\\n",
    "  --json-request=request.json"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
